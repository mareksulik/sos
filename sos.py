import streamlit as st
import requests
import json
import base64
import os
import pandas as pd
import time
from datetime import date, timedelta
import plotly.express as px
import numpy as np

# --- Konstanty API Endpointov ---
SEARCH_VOLUME_LIVE_URL = "https://api.dataforseo.com/v3/keywords_data/google_ads/search_volume/live"
LOCATIONS_URL = "https://api.dataforseo.com/v3/keywords_data/google_ads/locations"
LANGUAGES_URL = "https://api.dataforseo.com/v3/keywords_data/google_ads/languages"

# --- Helper funkcie pre z√≠skanie lok√°ci√≠ a jazykov (s cache) ---
# Funkcie zost√°vaj√∫ rovnak√©, ale bud√∫ volan√© s prihlasovac√≠mi √∫dajmi zo st.secrets
@st.cache_data
def load_locations(login, password):
    # Zabezpeƒçenie, ≈æe login a password nie s√∫ None alebo pr√°zdne re≈•azce
    if not login or not password: return [], "Ch√Ωbaj√∫ API prihlasovacie √∫daje v Streamlit Secrets."
    credentials = f"{login}:{password}"; encoded_credentials = base64.b64encode(credentials.encode()).decode()
    headers = {'Authorization': f'Basic {encoded_credentials}'}
    location_options = []; error_msg = None
    try:
        response = requests.get(LOCATIONS_URL, headers=headers, timeout=45)
        response.raise_for_status(); data = response.json()
        if data.get("tasks") and data["tasks"][0].get("status_code") == 20000:
            results = data["tasks"][0].get("result")
            if results:
                temp_locations = {}
                for item in results:
                    code = item.get("location_code"); name = item.get("location_name"); type = item.get("location_type")
                    display_name = f"{name}" + (f" ({type})" if type and type != "Country" else "")
                    if code and name: temp_locations[code] = {'name': name, 'type': type, 'display': display_name}
                location_options = sorted([(data['display'], code) for code, data in temp_locations.items()], key=lambda x: x[0])
            else: error_msg = "API (lok√°cie): ≈Ωiadne v√Ωsledky."
        # Detailnej≈°ie chybov√© hl√°senie pre neautorizovan√Ω pr√≠stup
        elif data.get("tasks") and data["tasks"][0].get("status_code") == 40101:
             error_msg = "API (lok√°cie): Chyba 40101 - Neautorizovan√©. Skontrolujte API prihlasovacie √∫daje v Streamlit Secrets."
        elif data.get("tasks"): status_code = data.get('tasks', [{}])[0].get('status_code', 'N/A'); status_message = data.get('tasks', [{}])[0].get('status_message', 'N/A'); error_msg = f"API (lok√°cie): K√≥d {status_code} - {status_message}"
        else: error_msg = "API (lok√°cie): Neoƒçak√°van√° odpoveƒè."
    except requests.exceptions.HTTPError as e:
        if e.response.status_code == 401:
             error_msg = "Chyba pri komunik√°cii s API (lok√°cie): 401 Unauthorized. Skontrolujte API prihlasovacie √∫daje v Streamlit Secrets."
        else:
             error_msg = f"Chyba pri komunik√°cii s API (lok√°cie): {e}"
    except requests.exceptions.RequestException as e: error_msg = f"Chyba pri komunik√°cii s API (lok√°cie): {e}"
    except Exception as e: error_msg = f"Neoƒçek√°van√° chyba pri naƒç√≠tan√≠ lok√°ci√≠: {e}"
    return location_options, error_msg

@st.cache_data
def load_languages(login, password):
    if not login or not password: return [], "Ch√Ωbaj√∫ API prihlasovacie √∫daje v Streamlit Secrets."
    credentials = f"{login}:{password}"; encoded_credentials = base64.b64encode(credentials.encode()).decode()
    headers = {'Authorization': f'Basic {encoded_credentials}'}
    language_options = []; error_msg = None
    try:
        response = requests.get(LANGUAGES_URL, headers=headers, timeout=20)
        response.raise_for_status(); data = response.json()
        if data.get("tasks") and data["tasks"][0].get("status_code") == 20000:
            results = data["tasks"][0].get("result")
            if results:
                temp_languages = {}
                for item in results:
                    code = item.get("language_code"); name = item.get("language_name")
                    if code and name: temp_languages[code] = name
                language_options = sorted([(name, code) for code, name in temp_languages.items()], key=lambda x: x[0])
            else: error_msg = "API (jazyky): ≈Ωiadne v√Ωsledky."
        elif data.get("tasks") and data["tasks"][0].get("status_code") == 40101:
             error_msg = "API (jazyky): Chyba 40101 - Neautorizovan√©. Skontrolujte API prihlasovacie √∫daje v Streamlit Secrets."
        elif data.get("tasks"): status_code = data.get('tasks', [{}])[0].get('status_code', 'N/A'); status_message = data.get('tasks', [{}])[0].get('status_message', 'N/A'); error_msg = f"API (jazyky): K√≥d {status_code} - {status_message}"
        else: error_msg = "API (jazyky): Neoƒçak√°van√° odpoveƒè."
    except requests.exceptions.HTTPError as e:
        if e.response.status_code == 401:
             error_msg = "Chyba pri komunik√°cii s API (jazyky): 401 Unauthorized. Skontrolujte API prihlasovacie √∫daje v Streamlit Secrets."
        else:
             error_msg = f"Chyba pri komunik√°cii s API (jazyky): {e}"
    except requests.exceptions.RequestException as e: error_msg = f"API (jazyky): Chyba komunik√°cie - {e}"
    except Exception as e: error_msg = f"Neoƒçek√°van√° chyba pri naƒç√≠tan√≠ jazykov: {e}"
    return language_options, error_msg

# --- Cachovan√° Funkcia pre API volanie search volume ---
@st.cache_data
def get_search_volume_live_with_history(login, password, kw_list_tuple, loc_code, lang_code, date_from, date_to):
    kw_list = list(kw_list_tuple); results_list = []; error_msg = None
    # Kontrola vstupov vr√°tane login/password
    if not all([login, password, kw_list, loc_code, lang_code, date_from, date_to]):
        # ≈†pecifickej≈°ia spr√°va ak ch√Ωbaj√∫ credentials
        if not login or not password:
            return None, "Chyba: Ch√Ωbaj√∫ API prihlasovacie √∫daje (pravdepodobne nie s√∫ nastaven√© v Streamlit Secrets)."
        return None, "Chyba: Ch√Ωbaj√∫ vstupn√© parametre pre API volanie."

    credentials = f"{login}:{password}"; encoded_credentials = base64.b64encode(credentials.encode()).decode()
    headers = { 'Authorization': f'Basic {encoded_credentials}', 'Content-Type': 'application/json' }
    post_data_payload = [{ "keywords": kw_list, "location_code": loc_code, "language_code": lang_code, "date_from": date_from.strftime("%Y-%m-%d"), "date_to": date_to.strftime("%Y-%m-%d"), "tag": "streamlit_cached_history_request" }]
    try:
        response = requests.post(SEARCH_VOLUME_LIVE_URL, headers=headers, json=post_data_payload, timeout=60)
        response.raise_for_status(); response_data = response.json()
        if response_data.get("tasks") and response_data["tasks"][0].get("status_code") == 20000:
            task_result_items = response_data["tasks"][0].get("result")
            if task_result_items:
                for item in task_result_items:
                    keyword = item.get("keyword"); monthly_searches_data = item.get("monthly_searches")
                    if not keyword or not monthly_searches_data: continue
                    for monthly_item in monthly_searches_data:
                        year = monthly_item.get("year"); month = monthly_item.get("month"); search_volume_value = monthly_item.get("search_volume")
                        if year and month and search_volume_value is not None:
                            try:
                                month_date = pd.to_datetime(f'{year}-{month:02d}-01')
                                request_start_date = pd.Timestamp(date_from); request_end_date = pd.Timestamp(date_to)
                                first_day_of_month = month_date.replace(day=1)
                                if first_day_of_month >= request_start_date.replace(day=1) and first_day_of_month <= request_end_date.replace(day=1):
                                    results_list.append({ "Keyword": keyword, "Date": month_date, "Search Volume": search_volume_value })
                            except ValueError: pass
            if not results_list and response_data["tasks"][0].get("status_code") == 20000:
                error_msg = "Varovanie: API nevr√°tilo ≈æiadne platn√© mesaƒçn√© historick√© d√°ta ('monthly_searches') v zadanom rozsahu d√°tumov."
        # Detailnej≈°ie chybov√© hl√°senie pre neautorizovan√Ω pr√≠stup
        elif response_data.get("tasks") and response_data["tasks"][0].get("status_code") == 40101:
             error_msg = f"Chyba API: K√≥d `{response_data['tasks'][0].get('status_code', 'N/A')}` - {response_data['tasks'][0].get('status_message', 'N/A')}. Skontrolujte API prihlasovacie √∫daje v Streamlit Secrets."
        elif response_data.get("tasks"): error_msg = f"Chyba API: K√≥d `{response_data['tasks'][0].get('status_code', 'N/A')}` - {response_data['tasks'][0].get('status_message', 'N/A')}"
        else: error_msg = "Chyba: API vr√°tilo neoƒçak√°van√∫ ≈°trukt√∫ru odpovede."; st.warning(f"Detail odpovede: {str(response_data)[:500]}")
    except requests.exceptions.Timeout: error_msg = "Chyba: Vypr≈°al ƒçasov√Ω limit pri ƒçakan√≠ na odpoveƒè z API."
    except requests.exceptions.HTTPError as e:
         if e.response.status_code == 401:
              error_msg = "Chyba pri komunik√°cii s API: 401 Unauthorized. Skontrolujte API prihlasovacie √∫daje v Streamlit Secrets."
         else:
              error_msg = f"Chyba pri komunik√°cii s API: {e}"
    except requests.exceptions.RequestException as e: error_msg = f"Chyba pri komunik√°cii s API: {e}";
    except json.JSONDecodeError: error_msg = f"Chyba: Nepodarilo sa dek√≥dova≈• JSON odpoveƒè.\n   Obsah (prv√Ωch 500 znakov): {response.text[:500]}"
    except Exception as e: error_msg = f"Nastala neoƒçak√°van√° chyba v spracovan√≠ API volania: {e}"
    if error_msg: return None, error_msg
    else:
        if not results_list: return None, "Varovanie: Nena≈°li sa ≈æiadne d√°ta pre zadan√© krit√©ri√°."
        return results_list, None

# --- Streamlit Aplik√°cia ---

st.set_page_config(page_title="Share of Search")
st.title("üìäüìà Share of Search Tool")

# --- PIN K√≥d Overenie ---
app_pin = st.secrets.get("app", {}).get("pin")
authenticated = False
pin_placeholder = st.empty() # Placeholder pre vstup PINu

if not app_pin:
    st.error("Chyba konfigur√°cie: PIN k√≥d nie je nastaven√Ω v Streamlit Secrets ([app] -> pin). Aplik√°cia nem√¥≈æe pokraƒçova≈•.")
    st.stop() # Zastav√≠ vykon√°vanie skriptu

entered_pin = pin_placeholder.text_input("üîë Zadajte pr√≠stupov√Ω PIN k√≥d:", type="password", key="pin_input")

if entered_pin:
    if entered_pin == app_pin:
        authenticated = True
        pin_placeholder.empty() # Skryje vstup pre PIN po √∫spe≈°nom overen√≠
    else:
        st.error("Nespr√°vny PIN k√≥d.")
        # Nepokraƒçuj ƒèalej, k√Ωm nie je spr√°vny PIN
elif not entered_pin:
     st.info("Pre pr√≠stup k aplik√°cii zadajte PIN k√≥d.")
     # Nepokraƒçuj ƒèalej, k√Ωm nie je zadan√Ω PIN

# --- Hlavn√° Aplik√°cia (zobraz√≠ sa len po √∫spe≈°nom overen√≠ PINom) ---
if authenticated:
    # Naƒç√≠tanie API prihlasovac√≠ch √∫dajov zo Streamlit Secrets
    # Pou≈æijeme .get() pre bezpeƒçnej≈°√≠ pr√≠stup, ak by kƒæ√∫ƒçe ch√Ωbali
    dataforseo_api_login = st.secrets.get("dataforseo", {}).get("login")
    dataforseo_api_password = st.secrets.get("dataforseo", {}).get("password")

    # --- Sidebar ---
    # Odstr√°nen√© vstupy pre API login/password
    st.sidebar.header("‚öôÔ∏è Nastavenia DataForSEO API")
    st.sidebar.info("API prihlasovacie √∫daje sa naƒç√≠tavaj√∫ zo Streamlit Secrets.")

    # --- Indik√°tor prihl√°senia ---
    login_status_placeholder = st.sidebar.empty()

    # Skontrolujeme, ƒçi boli credentials naƒç√≠tan√© zo secrets
    if dataforseo_api_login and dataforseo_api_password:
        # Volanie funkci√≠ s credentials zo secrets
        location_options, locations_error = load_locations(dataforseo_api_login, dataforseo_api_password)
        language_options, languages_error = load_languages(dataforseo_api_login, dataforseo_api_password)

        if not locations_error and not languages_error:
            login_status_placeholder.success("‚úÖ API Prihl√°senie OK (Lok√°cie a Jazyky naƒç√≠tan√©)")
        else:
            # Skontrolujeme, ƒçi chyba s√∫vis√≠ s autentifik√°ciou (401)
            is_auth_error = ("401" in str(locations_error)) or ("401" in str(languages_error))
            if is_auth_error:
                login_status_placeholder.error("‚ùå Chyba API Prihl√°senia! Skontrolujte credentials v Secrets.")
            else:
                 login_status_placeholder.warning("‚ö†Ô∏è Probl√©m s API. Skontrolujte chyby ni≈æ≈°ie.")
            if locations_error: st.sidebar.error(f"Lok√°cie: {locations_error}")
            if languages_error: st.sidebar.error(f"Jazyky: {languages_error}")
    else:
        login_status_placeholder.error("‚ùå API prihlasovacie √∫daje nen√°jden√© v Streamlit Secrets!")
        # Nastav√≠me options na pr√°zdne, aby sa selectboxy nezobrazili/boli disabled
        location_options, locations_error = [], "Ch√Ωbaj√∫ API prihlasovacie √∫daje."
        language_options, languages_error = [], "Ch√Ωbaj√∫ API prihlasovacie √∫daje."

    st.sidebar.markdown("---"); st.sidebar.header("‚ÑπÔ∏è Endpoint a Dokument√°cia");
    st.sidebar.markdown(f"Pou≈æ√≠va sa:"); st.sidebar.code(SEARCH_VOLUME_LIVE_URL, language=None)
    st.sidebar.markdown("[DataForSEO Dokument√°cia v3:](https://docs.dataforseo.com/v3/)")
    st.sidebar.markdown("[Dokument√°cia k Lok√°ci√°m](https://docs.dataforseo.com/v3/keywords_data/google_ads/locations/)")
    st.sidebar.markdown("[Dokument√°cia k Jazykom](https://docs.dataforseo.com/v3/keywords_data/google_ads/languages/)")
    st.sidebar.markdown("[Dokument√°cia k Search Volume](https://docs.dataforseo.com/v3/keywords_data/google_ads/search_volume/live/)")

    # --- Hlavn√° ƒças≈• ---
    st.header("üîç Zada≈• parametre vyhƒæad√°vania")

    col1, col2, col3 = st.columns(3)
    with col1:
        st.subheader("Kƒæ√∫ƒçov√© slov√°")
        # Pou≈æ√≠vame session_state pre zachovanie vstupu medzi behmi v r√°mci session
        if 'keywords_input' not in st.session_state: st.session_state.keywords_input = "isadore\ncastelli\nrapha\nmaap\npas normal studios"
        keywords_input = st.text_area("Zadajte kƒæ√∫ƒçov√© slov√°:", value=st.session_state.keywords_input, height=150, key="keywords_input_area")

    with col2:
        st.subheader("Lok√°cia")
        selected_location_code = None; selected_location_display = ""
        # Selectbox je disabled, ak ch√Ωbaj√∫ API kƒæ√∫ƒçe ALEBO sa nepodarilo naƒç√≠ta≈• lok√°cie
        loc_selectbox_disabled = not location_options or not dataforseo_api_login or not dataforseo_api_password
        if not loc_selectbox_disabled:
            loc_display_list = [opt[0] for opt in location_options]; loc_code_map = {opt[0]: opt[1] for opt in location_options}
            default_loc_name_display = next((name for name, code in location_options if code == 2703), loc_display_list[0] if loc_display_list else "") # Predvolen√° SK
            try: default_loc_index = loc_display_list.index(default_loc_name_display)
            except ValueError: default_loc_index = 0
            selected_location_display = st.selectbox("Vyberte lok√°ciu:", options=loc_display_list, index=default_loc_index, key="location_select", help="Zoznam naƒç√≠tan√Ω z API.")
            selected_location_code = loc_code_map.get(selected_location_display)
        else:
            st.info("API kƒæ√∫ƒçe nie s√∫ zadan√© alebo sa nepodarilo naƒç√≠ta≈• lok√°cie zo secrets. Zoznam lok√°ci√≠ nie je dostupn√Ω.")
            # Pr√≠padne zobraz√≠me chybu naƒç√≠tania lok√°ci√≠
            if locations_error and (dataforseo_api_login and dataforseo_api_password): # Zobraz chybu iba ak sme sa pok√∫sili naƒç√≠ta≈•
                 st.warning(f"Chyba pri naƒç√≠tan√≠ lok√°ci√≠: {locations_error}")

        st.subheader("Jazyk")
        selected_language_code = None; selected_language_display = ""
        lang_selectbox_disabled = not language_options or not dataforseo_api_login or not dataforseo_api_password
        if not lang_selectbox_disabled:
            lang_display_list = [opt[0] for opt in language_options]; lang_code_map = {opt[0]: opt[1] for opt in language_options}
            default_lang_name = next((name for name, code in language_options if code.lower() == 'sk'), lang_display_list[0] if lang_display_list else "") # Predvolen√° SK
            try: default_lang_index = lang_display_list.index(default_lang_name)
            except ValueError: default_lang_index = 0
            selected_language_display = st.selectbox("Vyberte jazyk:", options=lang_display_list, index=default_lang_index, key="language_select", help="Zoznam naƒç√≠tan√Ω z API.")
            selected_language_code = lang_code_map.get(selected_language_display)
        else:
            st.info("API kƒæ√∫ƒçe nie s√∫ zadan√© alebo sa nepodarilo naƒç√≠ta≈• jazyky zo secrets. Zoznam jazykov nie je dostupn√Ω.")
            if languages_error and (dataforseo_api_login and dataforseo_api_password):
                 st.warning(f"Chyba pri naƒç√≠tan√≠ jazykov: {languages_error}")

    with col3:
        st.subheader("ƒåasov√© okno hist√≥rie")
        today = date.today()
        default_end_date = today.replace(day=1) - timedelta(days=1)
        default_start_date = default_end_date.replace(year=default_end_date.year - 3) + timedelta(days=1)
        date_from_input = st.date_input("D√°tum od:", value=default_start_date, min_value=date(2015, 1, 1), max_value=default_end_date, key="date_from")
        date_to_input = st.date_input("D√°tum do:", value=default_end_date, min_value=date_from_input, max_value=default_end_date, key="date_to")

        st.subheader("Granularita Zobrazenia")
        # Pou≈æ√≠vame session_state aj pre granularitu
        if 'granularity_choice' not in st.session_state: st.session_state.granularity_choice = 'Roƒçne'
        granularity = st.radio( "Agregova≈• d√°ta:", options=['Roƒçne', '≈†tvr≈•roƒçne', 'Mesaƒçne'], index=['Roƒçne', '≈†tvr≈•roƒçne', 'Mesaƒçne'].index(st.session_state.granularity_choice), horizontal=True, key="granularity_radio" )
        st.session_state.granularity_choice = granularity # Ulo≈æ√≠me aktu√°lny v√Ωber

    keywords_list = [kw.strip() for kw in keywords_input.splitlines() if kw.strip()]

    st.info("Pozn√°mka: API vracia d√°ta len za obdobie, pre ktor√© s√∫ dostupn√© v Google Ads zdroji (typicky max. posledn√Ωch ~4-5 rokov), aj keƒè zvol√≠te star≈°√≠ 'D√°tum od'.")

    # Tlaƒçidlo je disabled ak ch√Ωbaj√∫ API kƒæ√∫ƒçe, lok√°cia alebo jazyk
    run_button_disabled = not selected_location_code or not selected_language_code or not dataforseo_api_login or not dataforseo_api_password

    # --- Cache Info Placeholder & Tlaƒçidlo ---
    # Vytvor√≠me kƒæ√∫ƒç pre session cache (bez credentials, tie s√∫ fixn√© per session/deploy)
    session_key = f"data_{tuple(sorted(keywords_list))}_{selected_location_code}_{selected_language_code}_{date_from_input}_{date_to_input}"
    cache_info_placeholder = st.empty()
    if session_key in st.session_state and st.session_state[session_key].get("data"):
         cache_info_placeholder.success("‚úÖ D√°ta pre tieto parametre s√∫ v cache session.")

    if st.button("üìä Z√≠ska≈• d√°ta a zobrazi≈• grafy", type="primary", disabled=run_button_disabled):
        if not keywords_list: st.warning("‚ö†Ô∏è Zadajte kƒæ√∫ƒçov√© slov√°.")
        elif date_from_input > date_to_input: st.error("üö® D√°tum 'od' nem√¥≈æe by≈• neskor≈°√≠ ako 'do'.")
        else:
            keywords_tuple = tuple(sorted(keywords_list))

            loaded_from_session = False
            # Skontrolujeme, ƒçi u≈æ m√°me d√°ta v session cache
            if session_key in st.session_state:
                results_data_list = st.session_state[session_key].get("data")
                error_msg = st.session_state[session_key].get("error")
                if results_data_list is not None or error_msg is not None:
                     cache_info_placeholder.success("‚úÖ Pou≈æ√≠vam d√°ta z cache session.")
                     loaded_from_session = True

            if not loaded_from_session:
                cache_info_placeholder.info("‚ÑπÔ∏è Cache session nen√°jden√°, vol√°m API...")
                with st.spinner("‚è≥ Z√≠skavam d√°ta z DataForSEO API..."):
                     # Vol√°me API funkciu s credentials naƒç√≠tan√Ωmi zo secrets
                     results_data_list, error_msg = get_search_volume_live_with_history(
                         dataforseo_api_login, dataforseo_api_password,
                         keywords_tuple, selected_location_code, selected_language_code, date_from_input, date_to_input
                     )
                     # Ulo≈æ√≠me v√Ωsledok (d√°ta alebo chybu) do session cache
                     st.session_state[session_key] = {"data": results_data_list, "error": error_msg}
                cache_info_placeholder.empty() # Vyma≈æeme info spr√°vu

            # Z√≠skame aktu√°lne d√°ta/chybu zo session state (ƒçi u≈æ z cache alebo po novom volan√≠)
            current_data = st.session_state[session_key].get("data")
            current_error = st.session_state[session_key].get("error")

            if not loaded_from_session and not current_error and current_data:
                st.success("‚úÖ D√°ta √∫spe≈°ne z√≠skan√© z API!")

    # --- ZOBRAZENIE V√ùSLEDKOV (Mimo 'if st.button', ale st√°le v 'if authenticated') ---
    # Zobraz√≠ v√Ωsledky, ak existuj√∫ v session state pre dan√Ω kƒæ√∫ƒç
    if session_key in st.session_state:
        current_data = st.session_state[session_key].get("data")
        current_error = st.session_state[session_key].get("error")

        if current_error: st.error(f"üö® Nastala chyba pri z√≠skavan√≠ d√°t:\n{current_error}")
        elif current_data:
            history_df_raw = pd.DataFrame(current_data); history_df_raw['Date'] = pd.to_datetime(history_df_raw['Date'])

            # --- Agreg√°cia d√°t ---
            try:
                history_df_agg = history_df_raw.copy()
                period_col_name = 'Period'; granularity_label = granularity.replace('e','√°')
                period_sort_key = None;
                if granularity == 'Roƒçne': history_df_agg[period_col_name] = history_df_agg['Date'].dt.year.astype(str); period_sort_key = lambda x: pd.to_numeric(x)
                elif granularity == '≈†tvr≈•roƒçne': history_df_agg[period_col_name] = history_df_agg['Date'].dt.to_period('Q').astype(str); period_sort_key = lambda x: pd.Period(x, freq='Q')
                else: history_df_agg[period_col_name] = history_df_agg['Date'].dt.strftime('%Y-%m'); period_sort_key = lambda x: pd.to_datetime(x, format='%Y-%m')

                period_volume_sum_df = history_df_agg.groupby([period_col_name, 'Keyword'], observed=False)['Search Volume'].sum().reset_index()
                total_period_volume_sum_df = period_volume_sum_df.groupby(period_col_name, observed=False)['Search Volume'].sum().reset_index().rename(columns={'Search Volume': 'Total Volume'})
                period_volume_avg_df = history_df_agg.groupby([period_col_name, 'Keyword'], observed=False)['Search Volume'].mean().reset_index().rename(columns={'Search Volume': 'Average Search Volume'})
                months_in_period = history_df_agg.groupby(period_col_name, observed=False)['Date'].nunique().rename('Num Months')
                total_period_volume_avg_df = pd.merge(total_period_volume_sum_df, months_in_period, on=period_col_name)
                total_period_volume_avg_df['Average Total Volume'] = total_period_volume_avg_df['Total Volume'] / total_period_volume_avg_df['Num Months']
                total_period_volume_avg_df = total_period_volume_avg_df[[period_col_name, 'Average Total Volume']]
                merged_period_df = pd.merge(period_volume_sum_df, total_period_volume_sum_df, on=period_col_name)
                merged_period_df['Share_Percent'] = 0.0; mask = merged_period_df['Total Volume'] > 0
                merged_period_df.loc[mask, 'Share_Percent'] = (merged_period_df['Search Volume'] / merged_period_df['Total Volume']) * 100
                merged_period_df.fillna({'Share_Percent': 0, 'Search Volume': 0}, inplace=True)
                # Filtrujeme a≈æ pre graf, aby sme mali v≈°etky d√°ta pre v√Ωpoƒçty
                # merged_df_plot = merged_period_df[merged_period_df['Total Volume'] > 0].copy()
                aggregation_successful = True
            except Exception as e:
                st.error(f"Chyba pri agreg√°cii d√°t podƒæa granularity '{granularity}': {e}"); st.exception(e)
                merged_period_df, period_volume_avg_df, total_period_volume_avg_df, period_volume_sum_df = pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()
                aggregation_successful = False

            # --- Zobrazenie grafov ---
            if aggregation_successful:
                total_volume_overall = None; keyword_order_list = None
                if not period_volume_sum_df.empty:
                     # Zorad√≠me KW podƒæa celkov√©ho objemu za cel√© obdobie
                     total_volume_overall = period_volume_sum_df.groupby('Keyword')['Search Volume'].sum().sort_values(ascending=False).index
                     keyword_order_list = list(total_volume_overall)

                # Filtrujeme d√°ta pre graf podielu a≈æ tu
                merged_df_plot = merged_period_df[merged_period_df['Total Volume'] > 0].copy()

                # --- Hlavn√Ω Graf: Podiel (%) ---
                st.markdown("---"); st.subheader(f"üìä {granularity} podiel | Lok√°cia: {selected_location_display}, Jazyk: {selected_language_display}")
                try:
                    if not merged_df_plot.empty:
                        unique_periods = sorted(merged_df_plot[period_col_name].unique(), key=period_sort_key)
                        fig_bar_share = px.bar(merged_df_plot, x=period_col_name, y='Share_Percent', color='Keyword', text='Share_Percent', barmode='stack', labels={'Share_Percent': '% Podiel', 'Keyword': 'Znaƒçka', period_col_name: granularity_label}, title="Share of Search (Podiel %)", category_orders={"Keyword": keyword_order_list, period_col_name: unique_periods})
                        fig_bar_share.update_layout(yaxis_title='% celkov√©ho objemu vyhƒæad√°vania', yaxis_ticksuffix="%", xaxis_type='category', legend_title_text='Znaƒçky', height=800)
                        fig_bar_share.update_traces(texttemplate='%{text:.1f}%', textposition='inside', insidetextanchor='middle', textfont_size=12)
                        st.plotly_chart(fig_bar_share, use_container_width=True)
                        try: img_bytes_bar = fig_bar_share.to_image(format="png", scale=3); st.download_button(label="üì• Stiahnu≈• Graf Podielu (PNG)", data=img_bytes_bar, file_name=f"sos_share_{selected_location_code}_{selected_language_code}_{granularity}.png", mime="image/png", key=f"download_share_{granularity}")
                        except Exception as img_e: st.warning(f"Chyba pri exporte PNG grafu Podielu: {img_e}. Skontrolujte 'kaleido' in≈°tal√°ciu.")
                    elif not current_error: st.warning(f"Nena≈°li sa ≈æiadne d√°ta na zobrazenie {granularity.lower()} grafu podielu (celkov√Ω objem bol 0).")
                except Exception as e: st.error(f"Chyba pri generovan√≠ {granularity.lower()} grafu podielu: {e}"); st.exception(e)

                st.markdown("---")
                st.header(f"Detailn√© anal√Ωzy ({granularity})")

                # Zobrazujeme detailn√© grafy iba ak m√°me nejak√© d√°ta v sum√°rnom DF
                if not period_volume_sum_df.empty:

                    # --- Graf: Celkov√Ω SUM√ÅRNY objem segmentu ---
                    st.subheader(f"üìà Celkov√Ω objem segmentu")
                    try:
                        if not total_period_volume_sum_df.empty and total_period_volume_sum_df['Total Volume'].sum() > 0:
                             unique_periods_sum_total = sorted(total_period_volume_sum_df[period_col_name].unique(), key=period_sort_key)
                             # Pou≈æijeme category_orders aj tu pre konzistentn√© zoradenie osi X
                             fig_total_sum_volume = px.bar(total_period_volume_sum_df, x=period_col_name, y='Total Volume', labels={'Total Volume': 'Celkov√Ω objem', period_col_name: granularity_label}, title=f"Celkov√Ω objem segmentu ({granularity.lower()}) - S√∫ƒçet", category_orders={period_col_name: unique_periods_sum_total})
                             fig_total_sum_volume.update_layout(yaxis_title='Celkov√Ω objem vyhƒæad√°vania (S√∫ƒçet)', xaxis_type='category', height=550)
                             fig_total_sum_volume.update_traces(texttemplate='%{y:,.0f}', textposition='outside')
                             st.plotly_chart(fig_total_sum_volume, use_container_width=True)
                             try: img_bytes_total_sum = fig_total_sum_volume.to_image(format="png", scale=3); st.download_button(label="üì• Stiahnu≈• Graf Celk. Obj. (S√∫ƒçet)", data=img_bytes_total_sum, file_name=f"sos_total_sum_{selected_location_code}_{selected_language_code}_{granularity}.png", mime="image/png", key=f"download_total_sum_{granularity}")
                             except Exception as img_e: st.warning(f"Chyba PNG (Celk. S√∫ƒçet): {img_e}.")
                        else: st.warning("N/A d√°ta pre graf celk. objemu (s√∫ƒçet).")
                    except Exception as e: st.error(f"Chyba pri generovan√≠ grafu celk. objemu (s√∫ƒçet): {e}")

                    # --- Graf: Celkov√Ω PRIEMERN√ù objem segmentu ---
                    st.subheader(f"üìâ Priemern√Ω mesaƒçn√Ω objem segmentu")
                    try:
                        if not total_period_volume_avg_df.empty and total_period_volume_avg_df['Average Total Volume'].sum() > 0:
                            unique_periods_avg_total = sorted(total_period_volume_avg_df[period_col_name].unique(), key=period_sort_key)
                            fig_avg_total_volume = px.bar(total_period_volume_avg_df, x=period_col_name, y='Average Total Volume', labels={'Average Total Volume': 'Priem. mesaƒçn√Ω objem', period_col_name: granularity_label}, title=f"Priemern√Ω mesaƒçn√Ω objem segmentu", category_orders={period_col_name: unique_periods_avg_total})
                            fig_avg_total_volume.update_layout(yaxis_title='Priemern√Ω mesaƒçn√Ω objem (AVG)', xaxis_type='category', height=550)
                            fig_avg_total_volume.update_traces(texttemplate='%{y:,.0f}', textposition='outside')
                            st.plotly_chart(fig_avg_total_volume, use_container_width=True)
                            try: img_bytes_avg_total = fig_avg_total_volume.to_image(format="png", scale=3); st.download_button(label="üì• Stiahnu≈• Graf Priem. Obj. Segmentu", data=img_bytes_avg_total, file_name=f"sos_avg_segment_{selected_location_code}_{selected_language_code}_{granularity}.png", mime="image/png", key=f"download_avg_segment_{granularity}")
                            except Exception as img_e: st.warning(f"Chyba PNG (Priem. Seg.): {img_e}.")
                        else: st.warning("N/A d√°ta pre graf priem. objemu segmentu.")
                    except Exception as e: st.error(f"Chyba pri generovan√≠ grafu priem. objemu segmentu: {e}")

                    # --- Graf: SUM√ÅRNY objem jednotliv√Ωch konkurentov ---
                    st.subheader(f"üíπ S√∫hrnn√Ω objem konkurentov")
                    try:
                         if not period_volume_sum_df.empty:
                              unique_periods_sum_comp = sorted(period_volume_sum_df[period_col_name].unique(), key=period_sort_key)
                              fig_line_sum_volume = px.line( period_volume_sum_df, x=period_col_name, y='Search Volume', color='Keyword', labels={'Search Volume': f'{granularity} objem (s√∫ƒçet)', 'Keyword': 'Znaƒçka', period_col_name: granularity_label}, title=f"{granularity} v√Ωvoj objemu (s√∫ƒçet)", category_orders={"Keyword": keyword_order_list, period_col_name: unique_periods_sum_comp}, markers=True )
                              fig_line_sum_volume.update_layout(yaxis_title=f'{granularity} objem (S√∫ƒçet)', legend_title_text='Znaƒçky', height=700)
                              fig_line_sum_volume.update_traces(mode="markers+lines", hovertemplate="<b>%{fullData.name}</b><br>Peri√≥da: %{x}<br>Objem (s√∫ƒçet): %{y:,.0f}<extra></extra>")
                              st.plotly_chart(fig_line_sum_volume, use_container_width=True)
                              try: img_bytes_sum_comp = fig_line_sum_volume.to_image(format="png", scale=3); st.download_button(label="üì• Stiahnu≈• Graf S√∫hrn. Obj. Konkurentov", data=img_bytes_sum_comp, file_name=f"sos_sum_competitor_{selected_location_code}_{selected_language_code}_{granularity}.png", mime="image/png", key=f"download_sum_comp_{granularity}")
                              except Exception as img_e: st.warning(f"Chyba PNG (S√∫hrn. Konk.): {img_e}.")
                         else: st.warning("N/A d√°ta pre graf s√∫hrn. objemu konkurentov.")
                    except Exception as e: st.error(f"Chyba pri generovan√≠ grafu objemu konkurentov (s√∫ƒçet): {e}")

                    # --- Graf: PRIEMERN√ù objem jednotliv√Ωch konkurentov ---
                    st.subheader(f"üìâ Priemern√Ω mesaƒçn√Ω objem konkurentov")
                    try:
                         if not period_volume_avg_df.empty:
                              unique_periods_avg_comp = sorted(period_volume_avg_df[period_col_name].unique(), key=period_sort_key)
                              fig_line_avg_volume = px.line( period_volume_avg_df, x=period_col_name, y='Average Search Volume', color='Keyword', labels={'Average Search Volume': f'Priem. mesaƒçn√Ω objem', 'Keyword': 'Znaƒçka', period_col_name: granularity_label}, title=f"{granularity} v√Ωvoj priemern√©ho mesaƒçn√©ho objemu", category_orders={"Keyword": keyword_order_list, period_col_name: unique_periods_avg_comp}, markers=True )
                              fig_line_avg_volume.update_layout(yaxis_title=f'Priem. mesaƒçn√Ω objem (AVG)', legend_title_text='Znaƒçky', height=700)
                              fig_line_avg_volume.update_traces(mode="markers+lines", hovertemplate="<b>%{fullData.name}</b><br>Peri√≥da: %{x}<br>Priem. objem: %{y:,.0f}<extra></extra>")
                              st.plotly_chart(fig_line_avg_volume, use_container_width=True)
                              try: img_bytes_avg_comp = fig_line_avg_volume.to_image(format="png", scale=3); st.download_button(label="üì• Stiahnu≈• Graf Priem. Obj. Konkurentov", data=img_bytes_avg_comp, file_name=f"sos_avg_competitor_{selected_location_code}_{selected_language_code}_{granularity}.png", mime="image/png", key=f"download_avg_comp_{granularity}")
                              except Exception as img_e: st.warning(f"Chyba PNG (Priem. Konk.): {img_e}.")
                         else: st.warning("N/A d√°ta pre graf priem. objemu konkurentov.")
                    except Exception as e: st.error(f"Chyba pri generovan√≠ grafu priem. objemu konkurentov: {e}")

                    # --- Vizualiz√°cia Rastov ---
                    st.subheader(f"üöÄ Tempo rastu ({granularity})")
                    st.markdown(f"##### Medziobdobov√Ω rast (%)") # H5 nadpis
                    try:
                         # Potrebujeme aspo≈à 2 peri√≥dy na v√Ωpoƒçet rastu
                         if len(period_volume_sum_df[period_col_name].unique()) > 1:
                              # Sort by period first (using the key), then keyword
                              period_growth_df = period_volume_sum_df.copy()
                              period_growth_df['SortKey'] = period_growth_df[period_col_name].apply(period_sort_key)
                              period_growth_df = period_growth_df.sort_values(by=['SortKey', 'Keyword']).drop(columns=['SortKey'])

                              period_growth_df['Prev Volume'] = period_growth_df.groupby('Keyword')['Search Volume'].shift(1)
                              mask_growth = (period_growth_df['Prev Volume'] > 0) & (pd.notna(period_growth_df['Prev Volume']))
                              period_growth_df['Period Growth (%)'] = np.nan
                              period_growth_df.loc[mask_growth, 'Period Growth (%)'] = ((period_growth_df['Search Volume'] - period_growth_df['Prev Volume']) / period_growth_df['Prev Volume']) * 100

                              # Handle cases where previous volume was 0 or NaN, but current is > 0 (infinite growth)
                              mask_inf = (period_growth_df['Prev Volume'] == 0) & (period_growth_df['Search Volume'] > 0) & (pd.notna(period_growth_df['Prev Volume']))
                              period_growth_df.loc[mask_inf, 'Period Growth (%)'] = np.inf

                              # Handle cases where volume drops to 0 from > 0 (-100% growth) - already covered by calculation
                              # Handle cases where both prev and current are 0 (NaN growth) - already handled by NaN default

                              # Prepare data for pivot (replace inf for calculation if needed, though pivot should handle it)
                              period_growth_pivot_data = period_growth_df.copy()

                              # Create pivot table
                              heatmap_data = period_growth_pivot_data.pivot(index='Keyword', columns=period_col_name, values='Period Growth (%)')

                              # Reindex rows based on overall volume and drop rows with all NaNs (keywords without growth data)
                              if keyword_order_list: heatmap_data = heatmap_data.reindex(index=keyword_order_list)
                              heatmap_data = heatmap_data.dropna(how='all', axis=0)

                              # Reindex columns based on period sort key
                              sorted_periods = sorted(heatmap_data.columns, key=period_sort_key)
                              heatmap_data = heatmap_data[sorted_periods]

                              if not heatmap_data.empty:
                                   # Prepare text labels: format numbers, show 'Inf%', handle NaN
                                   def format_growth(val):
                                        if pd.isna(val): return '-'
                                        if val == np.inf: return 'Inf%'
                                        if val == -np.inf: return '-Inf%' # Should not happen with volume >= 0
                                        return f"{val:.0f}%"
                                   text_labels = heatmap_data.applymap(format_growth).values

                                   # Prepare data for heatmap color scale: replace Inf/NaN with large/small numbers or map NaN to midpoint color
                                   # Let's cap the color scale for better visualization, e.g., -100% to +200%
                                   # Values outside this range will get the min/max color. NaN will be greyish.
                                   # Plotly imshow handles NaN by default (often grey)
                                   heatmap_display_data = heatmap_data.copy() # Use original data with NaN/Inf for display logic

                                   # Define color scale range
                                   color_min = -100
                                   color_max = 200
                                   color_mid = 0

                                   fig_heatmap = px.imshow( heatmap_display_data,
                                                            labels=dict(x=granularity_label, y="Znaƒçka", color="Rast (%)"),
                                                            title=f"Medziobdobov√Ω rast (%) - {granularity.lower()}",
                                                            text_auto=False, # We provide custom text
                                                            aspect="auto",
                                                            color_continuous_scale='RdYlGn', # Red-Yellow-Green
                                                            color_continuous_midpoint=color_mid,
                                                            range_color=[color_min, color_max] # Cap the color scale
                                                           )
                                   fig_heatmap.update_traces(
                                       text=text_labels, # Use formatted labels
                                       texttemplate="%{text}", # Display them as they are
                                       # Tooltip shows the actual numeric value (or NaN/Inf)
                                       hovertemplate="<b>%{y}</b><br>%{x}<br>Rast: %{customdata:.0f}%<extra></extra>",
                                       customdata=heatmap_data # Pass original data for hover
                                   )
                                   fig_heatmap.update_xaxes(side="bottom"); fig_heatmap.update_layout(height=max(450, len(heatmap_data.index)*40))
                                   st.plotly_chart(fig_heatmap, use_container_width=True)
                                   try: img_bytes_heatmap = fig_heatmap.to_image(format="png", scale=3); st.download_button(label="üì• Stiahnu≈• Heatmapu Rastu", data=img_bytes_heatmap, file_name=f"sos_growth_heatmap_{selected_location_code}_{selected_language_code}_{granularity}.png", mime="image/png", key=f"download_heatmap_{granularity}")
                                   except Exception as img_e: st.warning(f"Chyba PNG (Heatmap): {img_e}.")
                              else: st.info("Nebolo mo≈æn√© vypoƒç√≠ta≈• alebo zobrazi≈• medziobdobov√Ω rast (≈æiadne d√°ta po filtrovan√≠ alebo len jedna peri√≥da).")
                         else: st.info("Pre v√Ωpoƒçet medziobdobov√©ho rastu s√∫ potrebn√© aspo≈à dve ƒçasov√© peri√≥dy.")
                    except Exception as e: st.error(f"Chyba pri generovan√≠ heatmapy rastu: {e}"); st.exception(e)

                else: # Ak agreg√°cia vr√°tila pr√°zdny period_volume_sum_df
                    st.warning(f"Neboli n√°jden√© ≈æiadne agregovan√© d√°ta pre granularitu '{granularity}' na zobrazenie detailn√Ωch anal√Ωz.")

                st.markdown("---")
                # --- P√¥vodn√° Tabuƒæka Mesaƒçn√Ωch D√°t a CSV Download ---
                st.subheader("üìö Tabuƒæka p√¥vodn√Ωch d√°t (Mesaƒçne)")
                try:
                    if 'history_df_raw' in locals() and not history_df_raw.empty:
                         history_df_display = history_df_raw.copy(); history_df_display['Date'] = history_df_display['Date'].dt.strftime('%Y-%m')
                         st.dataframe(history_df_display[['Keyword', 'Date', 'Search Volume']].sort_values(by=['Keyword', 'Date']).reset_index(drop=True), height=300, use_container_width=True)
                    else: st.warning("P√¥vodn√© mesaƒçn√© d√°ta neboli n√°jden√© alebo spracovan√©.")
                except Exception as e: st.error(f"Chyba pri zobrazovan√≠ tabuƒæky: {e}")

                st.subheader("üì• Stiahnu≈• d√°ta (Mesaƒçne)")
                try:
                     if 'history_df_raw' in locals() and not history_df_raw.empty:
                          @st.cache_data # Cachovanie konverzie do CSV
                          def convert_df_to_csv(df): return df[['Keyword', 'Date', 'Search Volume']].sort_values(by=['Keyword','Date']).to_csv(index=False).encode('utf-8')
                          csv_data = convert_df_to_csv(history_df_raw); st.download_button(label="Stiahnu≈• mesaƒçn√© d√°ta ako CSV", data=csv_data, file_name=f'dataforseo_monthly_history_{selected_location_code}_{selected_language_code}.csv', mime='text/csv', key="download_csv")
                     else: st.warning("≈Ωiadne d√°ta na stiahnutie.")
                except Exception as e: st.error(f"Chyba pri pr√≠prave CSV na stiahnutie: {e}")

        # Pr√≠pad, kedy API nevr√°tilo d√°ta, ale ani explicitn√∫ chybu (z cache alebo priame volanie)
        elif current_error is None and not current_data:
             st.warning("ü§î API nevr√°tilo ≈æiadne v√Ωsledky pre zadan√© krit√©ri√°.")

    # Ak e≈°te nebol stlaƒçen√Ω gomb√≠k a nie je niƒç v cache pre tento kƒæ√∫ƒç
    elif session_key not in st.session_state and not run_button_disabled: # Pridan√° kontrola disabled stavu
         st.info("‚¨ÜÔ∏è Zadajte parametre a kliknite na tlaƒçidlo pre zobrazenie d√°t.")
    elif run_button_disabled and (dataforseo_api_login and dataforseo_api_password): # Ak s√∫ API kƒæ√∫ƒçe OK, ale ch√Ωba lok√°cia/jazyk
        st.warning("‚ö†Ô∏è Vyberte pros√≠m Lok√°ciu a Jazyk pre pokraƒçovanie.")


# Zobraz√≠ sa iba ak PIN nie je zadan√Ω alebo je nespr√°vny (a u≈æ sme zobrazili v√Ωzvu/chybu vy≈°≈°ie)
# else:
#    pass # U≈æ sme zobrazili info/error spr√°vu v bloku overenia PINu